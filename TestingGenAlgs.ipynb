{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import NeuralNet as nn\n",
    "import statistics as stats\n",
    "import pandas as pd\n",
    "#generates random population amount of random neural networks\n",
    "#intialize with varying weights for each layer but the same amount\n",
    "#of layers and nodes per layer\n",
    "#initialized with random activation functions as well\n",
    "#outputs neural nets as a list\n",
    "def genRandom(population, nodes_per_layer):\n",
    "    neuralNets=[]\n",
    "    layers=len(nodes_per_layer)\n",
    "    for p in range(0,population):\n",
    "        activation_funcs=[]\n",
    "        for q in range(0,layers-1):\n",
    "            alpha=random.randint(0,2)\n",
    "            if(alpha==2):\n",
    "                activation_funcs.append(3)\n",
    "            else:\n",
    "                activation_funcs.append(alpha)\n",
    "        net= nn.NeuralNet(activation_funcs,nodes_per_layer)\n",
    "        neuralNets.append(net)\n",
    "    return neuralNets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Initial training of random population before genetic algs do their\n",
    "#thing, pass in list of neural networks and the training dictionaries\n",
    "#optionally pass in iterations for back propogation to be ran\n",
    "#outputs updated neural nets \n",
    "def runBackProp(neuralNets, tics_to_inputs, tics_to_outputs, its=1):\n",
    "    #get all the tics\n",
    "    tics=tics_to_inputs.keys()\n",
    "    #for each neural network\n",
    "    for a in range(0,len(neuralNets)):\n",
    "        #choose amount of iterations to initially train neural nets\n",
    "        for b in range(0,its):\n",
    "            #for each tic\n",
    "            for b in tics:\n",
    "                #back propogate over each tic\n",
    "                inputs=tics_to_inputs[b]\n",
    "                outputs=tics_to_inputs[b]\n",
    "                neuralNets[a].backProp(inputs,outputs)\n",
    "    return neuralNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def meanAbsoluteDev(right, estimate):\n",
    "    total=0\n",
    "    div=len(right)\n",
    "    if(div==0):\n",
    "        return None\n",
    "    for a in range(0,div):\n",
    "        total+=abs(right[a]-estimate[a])\n",
    "    return total/div\n",
    "\n",
    "def medianAbsoluteDev(right, estimate):\n",
    "    even=False\n",
    "    listOfDiff=[]\n",
    "    length= len(right)\n",
    "    if(length==0):\n",
    "        return None\n",
    "    for a in range(length):\n",
    "        listOfDiff.append(abs(right[a]-estimate[a]))\n",
    "    listOfDiff=sorted(listOfDiff)\n",
    "    if length % 2 == 0:\n",
    "        val1= listOfDiff[int(length/2)]\n",
    "        val2= listOfDiff[(int(length/2))-1]\n",
    "        summ=val1+val2\n",
    "        return summ/2\n",
    "    else:\n",
    "        index= length/2\n",
    "        index= int(index-0.5)\n",
    "        return listOfDiff[index]\n",
    "\n",
    "def cheby(right, estimate):\n",
    "    listOfDiff=[]\n",
    "    for a in range(len(right)):\n",
    "        listOfDiff.append(abs(right[a]-estimate[a]))\n",
    "    return max(listOfDiff)\n",
    "\n",
    "\n",
    "def leastSquares(right, estimate):\n",
    "    listOfDiff=[]\n",
    "    total=0\n",
    "    for a in range(len(right)):\n",
    "        partial= right[a]-estimate[a]\n",
    "        square= partial*partial\n",
    "        total+=square\n",
    "    return total\n",
    "\n",
    "\n",
    "#takes in the actual values and what the neural net outputs\n",
    "#returns the fitness score for the neural net\n",
    "def fitness(actualVals,output):\n",
    "    mad= meanAbsoluteDev(actualVals, output)\n",
    "    #med= medianAbsoluteDev(actualVals, output)\n",
    "    #ls= 1/leastSquares(actualVals, output)\n",
    "    #cheb= 1/cheby(actualVals, output)\n",
    "    #sumOfAll=mad+med+ls+cheb\n",
    "    #fitScore=mad+cheb+ls\n",
    "    if(mad==None):\n",
    "        return None\n",
    "    mad=1/mad\n",
    "    return mad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass in single neural network and training data dictionaries\n",
    "#outputs a single fitness score for the neural net\n",
    "def singleScore(neuralNet, tics_to_outputs, tics_to_inputs):\n",
    "    scores=[]\n",
    "    for tic in tics_to_outputs.keys():\n",
    "        calc=[]\n",
    "        real=[]\n",
    "        for p in range(0,len(tics_to_inputs[tic])):\n",
    "            if(p<100):\n",
    "                calc.append(neuralNet.calculateOutput(tics_to_inputs[tic][p], single_input=True))\n",
    "                real.append(tics_to_outputs[tic][p])\n",
    "        if(fitness(real,calc)!=None):\n",
    "            scores.append(fitness(real, calc))\n",
    "    score=stats.mean(scores)\n",
    "    return score\n",
    "\n",
    "#Pass in list of neural networks and the training data dictionaries\n",
    "#returns a dictionary of the neural networks and their scores \n",
    "def cumulativeScore(neuralNets, tics_to_outputs, tics_to_inputs):\n",
    "    scoresDictionary={}\n",
    "    for i in neuralNets:\n",
    "        score=singleScore(i,tics_to_outputs, tics_to_inputs)\n",
    "        scoresDictionary.update({i:score})\n",
    "    return scoresDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the highest fitness score from the score dictionary\n",
    "def findMostFit(scoresDictionary):\n",
    "    scores=scoresDictionary.values()\n",
    "    return max(scores)\n",
    "\n",
    "#Takes a scores dictionary and normalizes them to values from\n",
    "#0 to 1 and returns said dictionary\n",
    "def normalizeScores(scoresDictionary):\n",
    "    maxVal=findMostFit(scoresDictionary)\n",
    "    #print(maxVal)\n",
    "    #total=0;\n",
    "    #i=0;\n",
    "    for a in scoresDictionary.keys():\n",
    "        score=scoresDictionary[a]\n",
    "        #total+=score\n",
    "        #i+=1\n",
    "        norm=score/maxVal\n",
    "        updater={a: norm}\n",
    "        scoresDictionary.update(updater)\n",
    "    #print(total/i)\n",
    "    return scoresDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#roulette wheel selection\n",
    "#input the scores dictionary of neural nets with their scores\n",
    "#and the amount of parents you want\n",
    "#returns a dictionary of the to be parent neural nets and their fitness scores\n",
    "def selection(scoresDictionary, amount):\n",
    "    selection={}\n",
    "    #normalize the scores\n",
    "    scoresDictionary2=normalizeScores(scoresDictionary)\n",
    "    #find sum of all the scores\n",
    "    valTotal=sum(scoresDictionary2.values())\n",
    "    #incrementer\n",
    "    val=0\n",
    "    #get keys \n",
    "    keys=scoresDictionary2.keys()\n",
    "    #create list of tuples\n",
    "    otherList=[]\n",
    "    for a in keys:\n",
    "        #get probability of reproduction\n",
    "        prob=scoresDictionary2[a]/valTotal\n",
    "        #multiply to 100 for simplicity\n",
    "        prob=prob*100\n",
    "        #add to val incrementer to get range of numbers\n",
    "        prob=prob+val\n",
    "        #create tuple\n",
    "        tup=(a,prob)\n",
    "        #update the list\n",
    "        otherList.append(tup)\n",
    "        #update the val incrementer\n",
    "        val=prob\n",
    "    #loop until we have all those selected to breed\n",
    "    while(len(selection)<amount):\n",
    "        #get a random val between 0 and 1 and multiply by 100\n",
    "        randVal=random.random()*100\n",
    "        for a in range(0,len(otherList)):\n",
    "            #get the value\n",
    "            val=otherList[a][1]\n",
    "            if(val>randVal):\n",
    "                break\n",
    "        #get the original score and neural network\n",
    "        keyToSee=otherList[a][0]\n",
    "        valToSee=scoresDictionary[keyToSee]\n",
    "        #add the selection\n",
    "        selection.update({keyToSee: valToSee})\n",
    "    return selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turns the inputted one dimensional matrix to a three dimensional \n",
    "#matrix with nodes_per_layer dimensions\n",
    "def turnOneToThree(listInOne, nodes_per_layer):\n",
    "    threeDList=[]\n",
    "    counter=0\n",
    "    for a in range(0,len(nodes_per_layer)-1):\n",
    "        twoDList=np.random.rand(nodes_per_layer[a],nodes_per_layer[a+1])\n",
    "        for b in range(0, nodes_per_layer[a]):\n",
    "            oneDList=np.zeros(nodes_per_layer[a+1])\n",
    "            for c in range(0,nodes_per_layer[a+1]):\n",
    "                oneDList[c]=listInOne[counter]\n",
    "                counter+=1\n",
    "            twoDList[b]=oneDList\n",
    "        threeDList.append(twoDList)\n",
    "    return threeDList\n",
    "\n",
    "\n",
    "#Turns the inputted three dimensional matrix into a single list\n",
    "def turnThreeToOne(matrix):\n",
    "    listToReturn=[]\n",
    "    for a in range(0,len(matrix)):\n",
    "        for b in range(0,len(matrix[a])):\n",
    "            for c in range(0, len(matrix[a][b])):\n",
    "                listToReturn.append(matrix[a][b][c])\n",
    "    return listToReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This function takes in a single neural network\n",
    "#Mutates its weights (not activation functions)\n",
    "#and returns the mutated neural net\n",
    "#inversion mutation\n",
    "def mutateThatJohn(neuralNetToMutate, nodes_per_layer):\n",
    "    #don't mutate the activation functions\n",
    "    activation_funcs=neuralNetToMutate.activation_functions\n",
    "    #creates new neural network\n",
    "    neuralNetToReturn= nn.NeuralNet(activation_funcs,nodes_per_layer)\n",
    "    weightsOf=neuralNetToMutate.weights\n",
    "    #turn weights to one dimension\n",
    "    weights1d= turnThreeToOne(weightsOf)\n",
    "    #get total amount of weights\n",
    "    totalAmtOfWeights=len(weights1d)\n",
    "    b=0\n",
    "    c=0\n",
    "    #loop until we get two different indices\n",
    "    while c==b:\n",
    "        b= random.randint(0,totalAmtOfWeights)\n",
    "        c= random.randint(0,totalAmtOfWeights)\n",
    "    #grab sublist from those indices\n",
    "    if b<c:\n",
    "        subList=weights1d[b:c]\n",
    "    else:\n",
    "        subList=weights1d[c:b]\n",
    "    #reverse the list\n",
    "    subList.reverse()\n",
    "    #replace elements in the list with reversed list\n",
    "    if b<c:\n",
    "        weights1d[b:c]=subList\n",
    "    else:\n",
    "        weights1d[c:b]=subList\n",
    "    #need it back in three dimensions\n",
    "    weightsBack=turnOneToThree(weights1d, nodes_per_layer)\n",
    "    #set mutated weights to new neural net\n",
    "    neuralNetToReturn.weights=weightsBack\n",
    "    #return mutated neural net\n",
    "    return neuralNetToReturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inputs two neural networks and a list of the nodes per layer \n",
    "#and crosses over the activation functions and weights of the\n",
    "#two neural networks and returns the network that is their child\n",
    "def crossover(neuralNetwork1, neuralNetwork2, nodes_per_layer):\n",
    "    #get the weights of each neural network\n",
    "    weights1=neuralNetwork1.weights\n",
    "    weights2=neuralNetwork2.weights\n",
    "    #get the activation functions of each neural network\n",
    "    activation1=neuralNetwork1.activation_functions\n",
    "    activation2=neuralNetwork2.activation_functions\n",
    "    #get number of activation functions\n",
    "    actives=len(activation1)\n",
    "    #get random int for one-point crossover of activation functions\n",
    "    cross=random.randint(0,actives)\n",
    "    activation_funcs=[]\n",
    "    for a in range(0,actives):\n",
    "        if a<cross:\n",
    "            activation_funcs.append(activation1[a])\n",
    "        else:\n",
    "            activation_funcs.append(activation2[a])\n",
    "    #create initial neural net to return\n",
    "    net= nn.NeuralNet(activation_funcs,nodes_per_layer)\n",
    "    #get total amount of weights\n",
    "    totalAmtOfWeights=0\n",
    "    for a in range(0,len(weights1)):\n",
    "        for b in range(0,len(weights1[a])):\n",
    "            for c in range(0,len(weights1[a][b])):\n",
    "                totalAmtOfWeights+=1\n",
    "    #grab two random ints for two-point crossover\n",
    "    b=0\n",
    "    c=0\n",
    "    while b==c:\n",
    "        b= random.randint(0,totalAmtOfWeights)\n",
    "        c= random.randint(0,totalAmtOfWeights)\n",
    "    #find the lower index\n",
    "    if b<c:\n",
    "        first=b\n",
    "        second=c\n",
    "    else:\n",
    "        first=c\n",
    "        second=b\n",
    "    counter=0\n",
    "    #crossover weights to child\n",
    "    for a in range(0,len(weights1)):\n",
    "        for b in range(0,len(weights1[a])):\n",
    "            for c in range(0,len(weights1[a][b])):\n",
    "                if counter<first:\n",
    "                    net.weights[a][b][c]=weights1[a][b][c]\n",
    "                elif counter>=first and counter<second:\n",
    "                    net.weights[a][b][c]=weights2[a][b][c]\n",
    "                else:\n",
    "                    net.weights[a][b][c]=weights1[a][b][c]\n",
    "                counter+=1\n",
    "    #return child\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Takes in a dictionary of those selected to be parents\n",
    "#Takes in a dictionary of all the neural nets and their scores\n",
    "#Takes in a population threshold (optionally takes in proportion to mutate)\n",
    "#Returns list of mutated to pass to next generation\n",
    "def mutateThoseJohns(population, selectionDictionary, scoresDictionary, nodes_per_layer, mutate=0.07):\n",
    "    #get the list of neural networks\n",
    "    listOfPotential=list(scoresDictionary.keys())\n",
    "    #get the list of the selected neural networks\n",
    "    listOfSelected=list(selectionDictionary.keys())\n",
    "    #find the length of the list of potential\n",
    "    totalLength=len(listOfPotential)\n",
    "    #set amount selected to 0\n",
    "    amountForMutate=0\n",
    "    #set amount to select to the proportion of the population needed to\n",
    "    #be mutated\n",
    "    amountToMutate=population*mutate\n",
    "    #list of mutated\n",
    "    listOfMutated=[]\n",
    "    #loop until all have been selected for mutation\n",
    "    while(amountForMutate<amountToMutate):\n",
    "        #get a random index to select\n",
    "        randomIndex=random.randint(0,totalLength-1)\n",
    "        #select it\n",
    "        neuralNetToMutate=listOfPotential[randomIndex]\n",
    "        #if it was not already selected\n",
    "        if(neuralNetToMutate not in listOfSelected):\n",
    "            #mutate it\n",
    "            neuralNetToMutate=mutateThatJohn(neuralNetToMutate, nodes_per_layer)\n",
    "            #add it to the list\n",
    "            listOfMutated.append(neuralNetToMutate)\n",
    "            #increment\n",
    "            amountForMutate+=1\n",
    "    #return list\n",
    "    return listOfMutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#generates next generation with population as the threshold\n",
    "#value for amount in the next generation and scoresDictionary that\n",
    "#maps neural nets to their fitness scores.\n",
    "#Returns list of next generation of neural nets\n",
    "def evaluation(population, selection, scoresDictionary, nodes_per_layer):\n",
    "    #start list of next population\n",
    "    nextPopulation=[]\n",
    "    #grab the parents we will be using\n",
    "    parents=list(selection.keys())\n",
    "    #mutate some of the population and append them for the next generation\n",
    "    nextPopulation.extend(mutateThoseJohns(population, selection, scoresDictionary, nodes_per_layer))\n",
    "    #append parents to the next population\n",
    "    nextPopulation.extend(parents)\n",
    "    #get list of neural networks\n",
    "    thelist1 = [(k, v) for k, v in scoresDictionary.items()] \n",
    "    #find the best neural net\n",
    "    best=findMostFitNeuralNet(thelist1)\n",
    "    nextPopulation.append(best[0])\n",
    "    #loop until we have a full next population\n",
    "    while len(nextPopulation)<population: \n",
    "        #parent indices\n",
    "        par1=0\n",
    "        par2=0\n",
    "        #until two different parents\n",
    "        while par1==par2:\n",
    "            par1=random.randint(0,len(parents)-1)\n",
    "            par2=random.randint(0,len(parents)-1)\n",
    "        #grab the parents\n",
    "        parent1=parents[par1]\n",
    "        parent2=parents[par2]\n",
    "        #create the child\n",
    "        child= crossover(parent1, parent2, nodes_per_layer)\n",
    "        #append the child\n",
    "        nextPopulation.append(child)\n",
    "    return nextPopulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Executes iterations worth of generations of neural networks\n",
    "def letsDoSomeGeneticAlgorithms(nodes_per_layer, population, tics_to_outputs, tics_to_inputs, amount=0.25,iterations=60):\n",
    "    #create initial population of neural networks\n",
    "    neuralNets=genRandom(population, nodes_per_layer)\n",
    "    #get amount of parents wanted\n",
    "    parents=amount*population\n",
    "    #set loop condition\n",
    "    i=0\n",
    "    #after iterations amount of iterations\n",
    "    while i<iterations:\n",
    "        #get the scores of the neural networks\n",
    "        scoresDictionary=cumulativeScore(neuralNets, tics_to_outputs, tics_to_inputs)\n",
    "        #grab parents for next generation\n",
    "        selectionDictionary=selection(scoresDictionary, parents)\n",
    "        #create next population\n",
    "        nextPop=evaluation(population, selectionDictionary, scoresDictionary, nodes_per_layer)\n",
    "        #set that to neuralNets\n",
    "        neuralNets=nextPop\n",
    "        #increment i\n",
    "        i+=1\n",
    "    #return the neural network loop\n",
    "    return neuralNets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=pd.read_csv(\"stock_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getInputs(tic, date, inputData): \n",
    "    listOfDates= list(inputData.index)\n",
    "    listOfNums=[x for x in range(0,len(listOfDates))]\n",
    "    datesToNums= dict(zip(listOfDates, listOfNums))\n",
    "    new_dict = dict([(value, key) for key, value in datesToNums.items()]) \n",
    "    try:\n",
    "        beginningIndex= datesToNums[date]\n",
    "    except:\n",
    "        return -1\n",
    "    endIndex=beginningIndex-20\n",
    "    if(endIndex<0):\n",
    "        return -1\n",
    "    relevantDates=[]\n",
    "    for i in range(endIndex, beginningIndex):\n",
    "        relevantDates.append(new_dict[i])\n",
    "    output=[]\n",
    "    for i in relevantDates:\n",
    "        output.append(inputData['close'][i])\n",
    "        output.append(inputData['range'][i])\n",
    "        output.append(inputData['singleDay'][i])\n",
    "        output.append(inputData['dayToDay'][i])\n",
    "        if i == relevantDates[-1]:\n",
    "            output.append(inputData['low'][i])\n",
    "            output.append(inputData['high'][i])\n",
    "            output.append(inputData['average'][i])\n",
    "            output.append(inputData['open'][i])\n",
    "            output.append(inputData['volume'][i])\n",
    "            output.append(inputData['twelveDay'][i])\n",
    "            output.append(inputData['twentySixDay'][i])\n",
    "            output.append(inputData['volumeEMA'][i])\n",
    "            output.append(inputData['fiftyTwoDayHigh'][i])\n",
    "            output.append(inputData['fiftyTwoWeekHigh'][i])\n",
    "            output.append(inputData['fiftyTwoDayLow'][i])\n",
    "            output.append(inputData['fiftyTwoWeekLow'][i])\n",
    "            output.append(inputData['fiftyTwoWeekAverage'][i])\n",
    "            output.append(inputData['fiftyTwoDayStandDev'][i])\n",
    "            output.append(inputData['fiftyTwoWeekStandDev'][i])\n",
    "    return np.array(output)\n",
    "    \n",
    "def inputsForBackProp(tics):\n",
    "    inputters=[]\n",
    "    outputters=[]\n",
    "    k=0\n",
    "    for tic in tics:\n",
    "        print(tics[k])\n",
    "        k+=1\n",
    "        tic=str(tic)\n",
    "        output_values = pd.read_csv('training/' + tic + r'.csv')\n",
    "        print(len(output_values))\n",
    "        #make sure we have data here\n",
    "        while(len(output_values)<1):\n",
    "            alpha=getRandomTics(1)\n",
    "            output_values=pd.read_csv('training/'+alpha[0]+r'.csv')\n",
    "        #creates an array of input vectors for a given stock and the training days\n",
    "        input_values = [0]*len(output_values.index)\n",
    "        data = pd.read_csv('normalized_data/' + tic + r'.csv')\n",
    "        data = data.set_index('date')\n",
    "        i = 0\n",
    "        for date in output_values.date:\n",
    "            input = getInputs(tic,date,data)\n",
    "            #catches error if not enough previous days\n",
    "            if type(input) ==type(-1):\n",
    "                output_values = output_values[output_values.date != date]\n",
    "                input_values = input_values[:-1]\n",
    "            else:\n",
    "                input_values[i] = input\n",
    "                i = i + 1\n",
    "            \n",
    "\n",
    "        inputters.append(input_values)\n",
    "        outputters.append(output_values['dayToDay'].to_numpy())\n",
    "    #map tics to their respective lists of inputs and outputs\n",
    "    input_dict=dict(zip(tics, inputters))\n",
    "    output_dict=dict(zip(tics,outputters))\n",
    "    #return list of both dicts\n",
    "    return [input_dict, output_dict]\n",
    "def inputsForTesting(tics):\n",
    "    inputters=[]\n",
    "    outputters=[]\n",
    "    k=0\n",
    "    for tic in tics:\n",
    "        print(tics[k])\n",
    "        k+=1\n",
    "        tic=str(tic)\n",
    "        output_values = pd.read_csv('testing/' + tic + r'.csv')\n",
    "        print(len(output_values))\n",
    "        while(len(output_values)<1):\n",
    "            alpha=getRandomTics(1)\n",
    "            output_values=pd.read_csv('testing/'+alpha[0]+r'.csv')\n",
    "        #creates an array of input vectors for a given stock and the training days\n",
    "        input_values = [0]*len(output_values.index)\n",
    "        data = pd.read_csv('normalized_data/' + tic + r'.csv')\n",
    "        data = data.set_index('date')\n",
    "        i = 0\n",
    "        for date in output_values.date:\n",
    "            input = getInputs(tic,date,data)\n",
    "            #catches error if not enough previous days\n",
    "            if type(input) ==type(-1):\n",
    "                output_values = output_values[output_values.date != date]\n",
    "                input_values = input_values[:-1]\n",
    "            else:\n",
    "                input_values[i] = input\n",
    "                i = i + 1\n",
    "            \n",
    "\n",
    "        inputters.append(input_values)\n",
    "        outputters.append(output_values['dayToDay'].to_numpy())\n",
    "    #map tics to their respective lists of inputs and outputs\n",
    "    input_dict=dict(zip(tics, inputters))\n",
    "    output_dict=dict(zip(tics,outputters))\n",
    "    #return list of both dicts\n",
    "    return [input_dict, output_dict]\n",
    "def findMostFitNeuralNet(thelist):\n",
    "    maxer=0\n",
    "    index=-1\n",
    "    for a in range(0,len(thelist)):\n",
    "        if(thelist[a][1]>maxer):\n",
    "            maxer=thelist[a][1]\n",
    "            index=a\n",
    "\n",
    "    return thelist[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directionPred(actual,predicted):\n",
    "    right=0;\n",
    "    wrong=0;\n",
    "    for i in range(0,len(actual)):\n",
    "        for j in range(0,len(actual[i])):\n",
    "            if(predicted[i][j]>0 and actual[i][j]>0):\n",
    "                right+=1\n",
    "            elif(predicted[i][j]<0 and actual[i][j]<0):\n",
    "                right+=1\n",
    "            #elif(predicted[i][j]==0 and actual[i][j]==0):\n",
    "                #right+=1\n",
    "            else:\n",
    "                wrong+=1\n",
    "    return [right,wrong]\n",
    "def averageError(actual, predicted):\n",
    "    error=0\n",
    "    ticker=0\n",
    "    for i in range(0,len(actual)):\n",
    "        for j in range(0,len(actual[i])):\n",
    "            val=actual[i][j]-predicted[i][j]\n",
    "            if(val<0):\n",
    "                val=val*(-1)\n",
    "            error+=val\n",
    "            ticker+=1\n",
    "    return error/ticker\n",
    "def bestPredictions(best):\n",
    "    actual=[]\n",
    "    predicted=[]\n",
    "    for tic in outputsForTesting[0].keys():\n",
    "        calc=[]\n",
    "        real=[]\n",
    "        for p in range(0,len(outputsForTesting[0][tic])):\n",
    "            calc.append(best[0].calculateOutput(outputsForTesting[0][tic][p], single_input=True))\n",
    "            real.append(outputsForTesting[1][tic][p])\n",
    "        actual.append(real)\n",
    "        predicted.append(calc)\n",
    "    return [actual, predicted]\n",
    "from statistics import mean\n",
    "def wholePopAveragePredictions(final):\n",
    "    actual=[]\n",
    "    predicted=[]\n",
    "    for tic in outputsForTesting[0].keys():\n",
    "        calc=[]\n",
    "        real=[]\n",
    "        for p in range(0,len(outputsForTesting[0][tic])):\n",
    "            temp=[]\n",
    "            for k in range(0,len(final)):\n",
    "                temp.append(final[k].calculateOutput(outputsForTesting[0][tic][p], single_input=True))\n",
    "\n",
    "            calc.append(mean(temp))\n",
    "            real.append(outputsForTesting[1][tic][p])\n",
    "        actual.append(real)\n",
    "        predicted.append(calc)\n",
    "    return [actual, predicted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tics=[]\n",
    "for i in range(0,len(frame['Ticker'])):\n",
    "    tics.append(frame['Ticker'][i])\n",
    "def getRandomTics(n):\n",
    "    i=0\n",
    "    ret=[]\n",
    "    while(i<n):\n",
    "        #get random index\n",
    "        k=random.randint(0,len(tics)-1)\n",
    "        ret.append(tics[k])\n",
    "        i+=1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBWB\n",
      "1490\n",
      "FTFT\n",
      "1990\n",
      "DOYU\n",
      "96\n",
      "RVT\n",
      "3500\n",
      "CPLP\n",
      "2270\n",
      "HYACW\n",
      "289\n",
      "CIBR\n",
      "803\n",
      "FLLCU\n",
      "82\n",
      "ZTR\n",
      "3500\n",
      "UFO\n",
      "147\n",
      "FDUSL\n",
      "356\n",
      "ESE\n",
      "3500\n",
      "IBUY\n",
      "668\n",
      "WHLM\n",
      "3500\n",
      "SBRA\n",
      "3106\n",
      "ICON\n",
      "3500\n",
      "ISEM\n",
      "229\n",
      "FBIO\n",
      "1447\n",
      "SGMO\n",
      "3462\n",
      "USX\n",
      "283\n",
      "KBWB\n",
      "589\n",
      "FTFT\n",
      "921\n",
      "DOYU\n",
      "46\n",
      "RVT\n",
      "2431\n",
      "CPLP\n",
      "967\n",
      "HYACW\n",
      "108\n",
      "CIBR\n",
      "353\n",
      "FLLCU\n",
      "35\n",
      "ZTR\n",
      "2334\n",
      "UFO\n",
      "60\n",
      "FDUSL\n",
      "149\n",
      "ESE\n",
      "2247\n",
      "IBUY\n",
      "289\n",
      "WHLM\n",
      "1809\n",
      "SBRA\n",
      "1389\n",
      "ICON\n",
      "2299\n",
      "ISEM\n",
      "95\n",
      "FBIO\n",
      "620\n",
      "SGMO\n",
      "1528\n",
      "USX\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "#data setup\n",
    "randos=getRandomTics(20)\n",
    "outputs=inputsForBackProp(randos)\n",
    "outputsForTesting=inputsForTesting(randos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.74572894943695\n",
      "44.74572894943695\n",
      "44.74572894943695\n",
      "49.782963884533665\n",
      "73.94772829310584\n",
      "73.94772829310584\n",
      "83.41638306320554\n",
      "83.41638306320554\n",
      "148.55146685175941\n",
      "159.52781372889058\n",
      "159.52781372889058\n",
      "159.52781372889058\n",
      "159.52781372889058\n",
      "159.52781372889058\n",
      "160.2806068152685\n",
      "171.4781377739353\n",
      "171.4781377739353\n",
      "171.4781377739353\n",
      "171.4781377739353\n",
      "171.4781377739353\n",
      "171.4781377739353\n",
      "171.4781377739353\n",
      "171.4781377739353\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n",
      "186.89167704846744\n"
     ]
    }
   ],
   "source": [
    "#Script to get results on finished neural net population\n",
    "#Set the nodes per layer which implicitly sets the amount of layers\n",
    "nodes_per_layer=[95,5,5,1]\n",
    "#Get the final population of neural nets\n",
    "final=letsDoSomeGeneticAlgorithms(nodes_per_layer, 60, outputs[1], outputs[0])\n",
    "#find their fitness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is how the most fit neural net faired on averaged: \n",
      "0.029618342647213167\n",
      "Here is how the most fit neural net faired directionally: \n",
      "Right: \n",
      "7856\n",
      "Wrong: \n",
      "10423\n",
      "Here is how the neural net pop faired on averaged: \n",
      "0.028882845419688243\n",
      "Here is how the neural net pop faired directionally: \n",
      "Right: \n",
      "7818\n",
      "Wrong: \n",
      "10461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a=cumulativeScore(final, outputs[1], outputs[0])\n",
    "#put this dictionary into a list of tuples\n",
    "thelist1 = [(k, v) for k, v in a.items()] \n",
    "#find the best neural net\n",
    "best=findMostFitNeuralNet(thelist1)\n",
    "#Find predictions on the best one and the population as a whole\n",
    "bestPreds=bestPredictions(best)\n",
    "popPreds=wholePopAveragePredictions(final)\n",
    "#Find Stats\n",
    "bestStats=directionPred(bestPreds[0],bestPreds[1])\n",
    "bestError=averageError(bestPreds[0],bestPreds[1])\n",
    "avStats=directionPred(popPreds[0],popPreds[1])\n",
    "avError=averageError(popPreds[0],popPreds[1])\n",
    "#Report Stats\n",
    "print(\"Here is how the most fit neural net faired on averaged: \")\n",
    "print(bestError)\n",
    "print(\"Here is how the most fit neural net faired directionally: \")\n",
    "print(\"Right: \")\n",
    "print(bestStats[0])\n",
    "print(\"Wrong: \")\n",
    "print(bestStats[1])\n",
    "print(\"Here is how the neural net pop faired on averaged: \")\n",
    "print(avError)\n",
    "print(\"Here is how the neural net pop faired directionally: \")\n",
    "print(\"Right: \")\n",
    "print(avStats[0])\n",
    "print(\"Wrong: \")\n",
    "print(avStats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<NeuralNet.NeuralNet at 0x1e714156ac8>, 198.88878430025702)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(0, len(best[0].weights)):\n",
    "    np.savetxt(\"{}new.csv\".format(k),best[0].weights[k], delimiter=', ', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.021303346883551396\n",
      "[1, 1, 3]\n",
      "1\n",
      "0.021279616065666564\n",
      "[0, 1, 0]\n",
      "2\n",
      "0.021278657860021578\n",
      "[0, 3, 1]\n",
      "3\n",
      "0.021272900897696546\n",
      "[0, 3, 3]\n",
      "4\n",
      "0.021272084664261337\n",
      "[1, 0, 1]\n",
      "5\n",
      "0.02129495289698527\n",
      "[0, 0, 3]\n",
      "6\n",
      "0.021270894649052227\n",
      "[1, 1, 0]\n",
      "7\n",
      "0.02129361390169323\n",
      "[1, 3, 0]\n",
      "8\n",
      "0.021278238895052114\n",
      "[3, 1, 1]\n",
      "9\n",
      "0.021270778272537347\n",
      "[1, 1, 3]\n",
      "10\n",
      "0.02129037004368542\n",
      "[0, 1, 3]\n",
      "11\n",
      "0.021311310275228798\n",
      "[3, 3, 1]\n",
      "12\n",
      "0.021272504620847645\n",
      "[0, 0, 0]\n",
      "13\n",
      "0.02129449220790419\n",
      "[0, 3, 3]\n",
      "14\n",
      "0.02127242150931598\n",
      "[0, 3, 1]\n",
      "15\n",
      "0.021290487021799497\n",
      "[1, 3, 1]\n",
      "16\n",
      "0.021288317527989445\n",
      "[1, 0, 0]\n",
      "17\n",
      "0.021290489187046173\n",
      "[0, 1, 1]\n",
      "18\n",
      "0.021310243382967498\n",
      "[3, 0, 1]\n",
      "19\n",
      "0.021270489711816366\n",
      "[0, 1, 3]\n",
      "20\n",
      "0.021270113668412766\n",
      "[3, 1, 3]\n",
      "21\n",
      "0.02153159615088308\n",
      "[1, 3, 3]\n",
      "22\n",
      "0.02137257179757528\n",
      "[3, 1, 3]\n",
      "23\n",
      "0.021301626434111338\n",
      "[0, 1, 3]\n",
      "24\n",
      "0.021274136326675658\n",
      "[3, 0, 3]\n",
      "25\n",
      "0.021323123145638216\n",
      "[3, 3, 0]\n",
      "26\n",
      "0.02127127913170506\n",
      "[1, 0, 0]\n",
      "27\n",
      "0.021290153471811527\n",
      "[0, 0, 1]\n",
      "28\n",
      "0.021291478105115866\n",
      "[1, 0, 3]\n",
      "29\n",
      "0.021296309981944542\n",
      "[1, 1, 3]\n",
      "Here is how the most fit neural net faired on averaged: \n",
      "0.02129761995629973\n",
      "Here is how the most fit neural net faired directionally: \n",
      "Right: \n",
      "7773.8\n",
      "Here is how the neural net pop faired on averaged: \n",
      "0.02134811998875385\n",
      "Here is how the neural net pop faired directionally: \n",
      "Right: \n",
      "7825.9\n"
     ]
    }
   ],
   "source": [
    "bestStats=[]\n",
    "bestError=[]\n",
    "avStats=[]\n",
    "avError=[]\n",
    "for touchdown in range(0,30):\n",
    "    #Script to get results on finished neural net population\n",
    "    #Set the nodes per layer which implicitly sets the amount of layers\n",
    "    nodes_per_layer=[95,1,1,1]\n",
    "    #Get the final population of neural nets\n",
    "    final=letsDoSomeGeneticAlgorithms(nodes_per_layer, 60, outputs[1], outputs[0])\n",
    "    #find their fitness scores\n",
    "    a=cumulativeScore(final, outputs[1], outputs[0])\n",
    "    #put this dictionary into a list of tuples\n",
    "    thelist1 = [(k, v) for k, v in a.items()] \n",
    "    #find the best neural net\n",
    "    best=findMostFitNeuralNet(thelist1)\n",
    "    #Find predictions on the best one and the population as a whole\n",
    "    bestPreds=bestPredictions(best)\n",
    "    popPreds=wholePopAveragePredictions(final)\n",
    "    #Find Stats\n",
    "    bestStats.append(directionPred(bestPreds[0],bestPreds[1]))\n",
    "    bestError.append(averageError(bestPreds[0],bestPreds[1]))\n",
    "    print(touchdown)\n",
    "    print(bestError[touchdown])\n",
    "    print(best[0].activation_functions)\n",
    "    avStats.append(directionPred(popPreds[0],popPreds[1]))\n",
    "    avError.append(averageError(popPreds[0],popPreds[1]))\n",
    "#Report Stats\n",
    "right=0\n",
    "righto=0\n",
    "for yes in range(0,len(bestStats)):\n",
    "    right+=bestStats[yes][0]\n",
    "for no in range(0,len(avStats)):\n",
    "    righto+=avStats[no][0]\n",
    "right=right/len(bestStats)\n",
    "righto=righto/len(avStats)\n",
    "print(\"Here is how the most fit neural net faired on averaged: \")\n",
    "print(sum(bestError)/len(bestError))\n",
    "print(\"Here is how the most fit neural net faired directionally: \")\n",
    "print(\"Right: \")\n",
    "print(right)\n",
    "print(\"Here is how the neural net pop faired on averaged: \")\n",
    "print(sum(avError)/len(avError))\n",
    "print(\"Here is how the neural net pop faired directionally: \")\n",
    "print(\"Right: \")\n",
    "print(righto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "def exportNeuralNet(best, name, leng):\n",
    "    path='/NeuralNetworks/' + name + '.npy';\n",
    "    np.savez(path,best[0].weights[0], best[0].weights[1], best[0].weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18279, 2624]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pen=0\n",
    "z=0\n",
    "for i in range(0,len(popPreds[1])):\n",
    "    for j in range(0,len(popPreds[1][i])):\n",
    "        pen+=1\n",
    "        if(bestPreds[0][i][j]==0):\n",
    "            z+=1\n",
    "[pen,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15655"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pen-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best[0].activation_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
